When understanding about storage in docker we see 2 concepts
Storage Drivers
when we first install docker it stores its data in /var/lib/docker
inside docker their are multiple different folders to store container, volumes , image etc
we learned the docker uses layered architecture to build docker images. docker efficiently saves spaces by when we create another image which has same base layers it fetches them from cache just updating the changed layers hence saving space. 
when we run docker build command it creates a docker image and when we use docker run command it create one extra layer named Container layer which stores the data generated by the container it is deleted when the container is stopped

to persist the data created by the container we use docker volumes 
steps:
==docker volume create data_volume==
to store data inside volume
volume mounting: (mount the docker host data to a volume)
==docker run -v data_volume:/var/lib/mysql mysql==
all the data created in var/lib/mysql will be stored in data_volume
bind mounting: (mount the docker host data to a directory)
==docker run -v /data/mysql:/var/lib/mysql mysql==
same command now but more verbose
==docker run \
--mount type=bind,source=/data/mysql,target=/var/lib/mysql mysql==

Docker uses storage drivers to maintain the layered architecture, moving files across layers .copying files etc. some common storage drivers are:
AUFS
Overlay
Overlay2
ZFS

Volume Drivers
A **Docker volume driver** is a plugin that manages volumes for Docker containers, allowing data to persist beyond the lifecycle of a container. It enables integration with external storage systems like cloud-based storage, networked file systems, and third-party volume management tools.
Features:
- **Persistent Storage**: Ensures data is retained even if the container is removed.
- **Storage Abstraction**: Allows Docker to interact with different storage backends without modifying container configurations.
- **Multi-host Support**: Some volume drivers enable volume sharing across multiple Docker hosts.
common volume drivers:
1. **local (default)** – Uses the host filesystem.
2. **nfs** – Mounts a Network File System (NFS) share.
3. **flocker** – Provides cluster-wide storage for multi-host Docker setups.
4. **rexray** – Works with cloud providers like AWS, Azure, and GCP.
5. **portworx** – A distributed storage system for Kubernetes and Docker.
Container runtime interface:
It is a standard that defines how an orchestration solution like kubernetes  will communicate with container runtimes like docker so when new container runtimes are created they just have to follow CRI standards. 
similarly container networking interface was introduced so that networking vendors can create plugins based on CNI standards
and eventually
container storage interface was developed so that org can write their own drivers to work with kubernetes following CSI standards.
CSI introduced rpc(remote procedure calls ) which will be called by the kubernetes and it must be implemented by the storage drivers

Volumes in kubernetes
Kubernetes _volumes_ provide a way for containers in a pods to access and share data via the filesystem
volume.yaml
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: random
spec:
  containers:
    - name: alpine
      image: alpine
      command: ["/bin/sh","-c"]
	  args: ["shuf -i 0-100 -n 1 >> /opt/number.out;"]
      volumeMounts:
        - name: datavolume
          mountPath: /opt
  volumes:
    - name: datavolume
      hostPath:
		path: /data
		type: Directory
```

Persistent volume in kubernetes
by creating volumes by method above we configure the volumes within the pod definition file .In the large environment with lots of users and lots of pods, we cannot configure storage for each pod
A persistent volume help us by creating a cluster wide pool of storage volumes configures by an administrator to be used by users deploying applications on the cluster
pv.yaml
```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
	name:pv
spec:
	accessModes:
		- ReadWriteOnce
	capacity:
		storage: 1Gi
	hostPath:
		path: /tmp/data
	awsElasticBlockStore:
		volumeID: <volume-id>
		fsType: ext4
```
Persistent volume claim
it is a seperate object from kubernetes namespace. PV is created by a administrator and claims are created by the users. Once the claims are created kubernetes binds the persistent volumes to the claims based on the request. claim can only be bound to single persistent volume. 
During binding kubernetes finds the suitable persistent for the claim request if there are multiple matches you can also use labels to bind to a volume. if no volume the claim will be in pendng state
claim.yaml
```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
	name:pvc
spec:
	accessModes:
		- ReadWriteOnce
	resources:
		requests:
			storage: 500Mi
```
when we delete a claim by default the volume would have to be manually deleted
Once you create a PVC use it in a POD definition file by specifying the PVC Claim name under persistentVolumeClaim section in the volumes section like this:
pod.yaml
```yaml
apiVersion: v1
kind: Pod
metadata:
	name: mypod
spec:
	containers:
	- name: myfrontend
	  image: nginx
	  volumeMounts:
      - mountPath: "/var/www/html"
        name: mypd
	volumes:
	  - name: mypd
	persistentVolumeClaim:
		claimName: myclaim
```
Storage class
with it you can define a provisioner like google storage that can automatically provision storage on google cloud and attach that to pods when claim is made . we wont have to manually create a pv 
```yaml
apiVersion: Storage.k8s.io/v1
kind: StorageClass
metadata:
	name: google-storage
provisioner: kubernetes.io/gce-pd
parametere:
	type: pd-standard
	replication-type: none
```